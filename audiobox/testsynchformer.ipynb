{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707f4c3-8037-4161-93ac-f4cc0d1c86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://huggingface.co/hkchengrex/MMAudio/resolve/main/ext_weights/synchformer_state_dict.pth?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0b8fb6-d608-42a4-9d58-97ac39d943af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "from mmaudio.ext.synchformer import Synchformer\n",
    "\n",
    "synchformer = Synchformer()\n",
    "synchformer.eval()\n",
    "synchformer.to('cuda')\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbcb1ce-a5c5-4f8e-b1c0-6a24ecd3caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = './synchformer_state_dict.pth'\n",
    "synchformer.load_state_dict(torch.load(ckpt_path, weights_only=True, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98470e18-af1a-4a32-b660-0edd160c0ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 40, 768])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode_video_with_sync(x: torch.Tensor, batch_size: int = -1) -> torch.Tensor:\n",
    "    # x: (B, T, C, H, W) H/W: 384\n",
    "    b, t, c, h, w = x.shape\n",
    "    assert c == 3 and h == 224 and w == 224\n",
    "\n",
    "    # partition the video\n",
    "    segment_size = 16\n",
    "    step_size = 8\n",
    "    num_segments = (t - segment_size) // step_size + 1\n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        segments.append(x[:, i * step_size:i * step_size + segment_size])\n",
    "    x = torch.stack(segments, dim=1)  # (B, S, T, C, H, W)\n",
    "\n",
    "    outputs = []\n",
    "    if batch_size < 0:\n",
    "        batch_size = b\n",
    "    x = rearrange(x, 'b s t c h w -> (b s) 1 t c h w')\n",
    "    for i in range(0, b * num_segments, batch_size):\n",
    "        outputs.append(synchformer(x[i:i + batch_size]))\n",
    "    x = torch.cat(outputs, dim=0)\n",
    "    x = rearrange(x, '(b s) 1 t d -> b (s t) d', b=b)\n",
    "    return x\n",
    "\n",
    "sample_video = torch.randn((2, 24*2, 3, 224, 224)).to('cuda')\n",
    "out = encode_video_with_sync(sample_video)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f21475-029e-49cb-b3ea-9f1c1f65cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "xs = torch.randn((2, 768, 40))\n",
    "ds = F.interpolate(xs, size=43, mode='nearest-exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d96ee82-8fee-4b14-8651-e0e9b72992dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768, 43])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52a4ac-1cf4-4d23-ae65-de4ec13d43e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
