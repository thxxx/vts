{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707f4c3-8037-4161-93ac-f4cc0d1c86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://huggingface.co/hkchengrex/MMAudio/resolve/main/ext_weights/synchformer_state_dict.pth?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0b8fb6-d608-42a4-9d58-97ac39d943af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "from mmaudio.ext.synchformer import Synchformer\n",
    "\n",
    "synchformer = Synchformer()\n",
    "synchformer.eval()\n",
    "synchformer.to('cuda')\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbcb1ce-a5c5-4f8e-b1c0-6a24ecd3caf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = './synchformer_state_dict.pth'\n",
    "synchformer.load_state_dict(torch.load(ckpt_path, weights_only=True, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98470e18-af1a-4a32-b660-0edd160c0ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 84.7048,  -1.4123, -10.7278,  ...,   3.9687,  -9.1473,  22.9747],\n",
       "         [ 74.0585,  -5.5176, -10.5255,  ...,  10.1483, -14.2576,  11.3589],\n",
       "         [ 70.0251,  -4.2739, -11.0044,  ...,   9.6163, -15.3478,   8.3899],\n",
       "         ...,\n",
       "         [ 75.0216,  -1.3465,  -8.5869,  ...,  10.9712, -15.1799,   9.8734],\n",
       "         [ 76.8856,  -3.9404,  -8.5720,  ...,  12.5994, -15.7083,  11.6734],\n",
       "         [ 85.9017,  -5.6924,  -8.7210,  ...,  12.3665, -15.2313,  14.9834]],\n",
       "\n",
       "        [[ 85.2611,  -1.3105, -11.2254,  ...,   1.9710,  -9.3639,  24.2098],\n",
       "         [ 74.5716,  -4.4702, -11.0290,  ...,   9.0892, -14.2841,  11.1912],\n",
       "         [ 70.9878,  -3.2782,  -8.4976,  ...,   9.1781, -15.5308,   8.9840],\n",
       "         ...,\n",
       "         [ 73.8121,  -2.0369,  -8.7236,  ...,  10.9246, -14.8486,   8.1427],\n",
       "         [ 76.5317,  -3.0007,  -8.0928,  ...,  10.7722, -15.3132,  12.7538],\n",
       "         [ 88.6785,  -7.6399, -10.5945,  ...,  14.3221, -15.2961,  16.3075]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode_video_with_sync(x: torch.Tensor, batch_size: int = -1) -> torch.Tensor:\n",
    "    # x: (B, T, C, H, W) H/W: 384\n",
    "    b, t, c, h, w = x.shape\n",
    "    assert c == 3 and h == 224 and w == 224\n",
    "\n",
    "    # partition the video\n",
    "    segment_size = 16\n",
    "    step_size = 8\n",
    "    num_segments = (t - segment_size) // step_size + 1\n",
    "    segments = []\n",
    "    for i in range(num_segments):\n",
    "        segments.append(x[:, i * step_size:i * step_size + segment_size])\n",
    "    x = torch.stack(segments, dim=1)  # (B, S, T, C, H, W)\n",
    "\n",
    "    outputs = []\n",
    "    if batch_size < 0:\n",
    "        batch_size = b\n",
    "    x = rearrange(x, 'b s t c h w -> (b s) 1 t c h w')\n",
    "    for i in range(0, b * num_segments, batch_size):\n",
    "        outputs.append(synchformer(x[i:i + batch_size]))\n",
    "    x = torch.cat(outputs, dim=0)\n",
    "    x = rearrange(x, '(b s) 1 t d -> b (s t) d', b=b)\n",
    "    return x\n",
    "\n",
    "sample_video = torch.randn((2, 24*2, 3, 224, 224)).to('cuda')\n",
    "encode_video_with_sync(sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f21475-029e-49cb-b3ea-9f1c1f65cf07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
