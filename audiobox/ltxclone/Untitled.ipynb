{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db95634d-0830-40cb-9a0e-5c71953f6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltx_video.inference import infer, InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2bd336-5bd8-4587-9f10-5ff77379532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padded dimensions: 768x512x33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53646f5b82b44270942fa9b61d9310cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/788 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a2cdf5448e4ffe888dae6cfcd9785c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d338375683a4b3ea1f5e1f26dca8633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d966048ae22463f97663b57a3698767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27464b82f8f4c9ebe70b8ebbb37a86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/9.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4f699f7f8a4fca963ad41be6b3774d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075b58d5dad4458c936e2ea0e703d659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b944420752bb4b7a8533124a92399e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7da4b01251c46c389cf43f18b4b48c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d46f239c6a40b59a03ef47d5724e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb66a847d7c5457194a2b37b68da5d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/LTX-Video/ltx_video/pipelines/pipeline_ltx_video.py:1301: FutureWarning: Accessing config attribute `in_channels` directly via 'Transformer3DModel' object attribute is deprecated. Please access 'in_channels' over 'Transformer3DModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  out_channels=self.transformer.in_channels\n",
      "Output saved to output.mp4/video_output_0_a-cat_171198_768x512x33_0.mp4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "infer(\n",
    "    InferenceConfig(\n",
    "        pipeline_config=\"configs/ltxv-2b-0.9.6-distilled.yaml\",\n",
    "        prompt=\"a cat\",\n",
    "        height=512,\n",
    "        width=768,\n",
    "        num_frames=24,\n",
    "        output_path=\"output.mp4\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f13eb-5bce-4fba-b881-2ff630b520fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padded dimensions: 512x768x9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e95b9dba854ba2802152614ba3f1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8601a0ef5941dcb84833b31a10e17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_6.mp4/video_output_0_a-backroom-walking_171198_512x768x6_2.mp4\n",
      "Padded dimensions: 512x768x9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fps -  17.844921350479126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a29704c0be48f695c14d9ff6f87aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b47becce814e6c805680dfa61d0407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_6.mp4/video_output_0_a-backroom-walking_171198_512x768x6_3.mp4\n",
      "Padded dimensions: 512x768x9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fps -  17.28830075263977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e348788f996465298d789d69dc68f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee66967644b46b186abaa74fcf801e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_6.mp4/video_output_0_a-backroom-walking_171198_512x768x6_4.mp4\n",
      "Padded dimensions: 512x768x9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fps -  17.161258459091187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80715ce5566340bdb39719120dc8675a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33db23c753604431a53a5358d17fa696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_6.mp4/video_output_0_a-backroom-walking_171198_512x768x6_5.mp4\n",
      "Padded dimensions: 512x768x9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fps -  17.5438289642334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1612dfd0ed4d4bafb62cf963ef7e2cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c0329164974d96a3e616d71e169d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_6.mp4/video_output_0_a-backroom-walking_171198_512x768x6_6.mp4\n",
      "Padded dimensions: 512x768x17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fps -  17.02604579925537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd7dcc2676c45d6837379df920c0efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35429a52165d4a5fa710a66573ca59e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_12.mp4/video_output_0_a-backroom-walking_171198_512x768x12_1.mp4\n",
      "Padded dimensions: 512x768x17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 fps -  18.603000164031982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d87dc46454445c78e901d3239bf7a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397c50936a77447187d2365fd38ef117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_12.mp4/video_output_0_a-backroom-walking_171198_512x768x12_2.mp4\n",
      "Padded dimensions: 512x768x17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 fps -  17.174828052520752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39a87256a16404a946dd052bcc884cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b682a42648454ef08b9e8b8a84a68a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output saved to output_12.mp4/video_output_0_a-backroom-walking_171198_512x768x12_3.mp4\n",
      "Padded dimensions: 512x768x17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 fps -  18.104973793029785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c2d6ce980f47bcb48d5f92356beeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for fps in [6, 12, 24, 36]:\n",
    "    for _ in range(5):\n",
    "        st = time.time()\n",
    "        infer(\n",
    "            InferenceConfig(\n",
    "                pipeline_config=\"configs/ltxv-2b-0.9.6-distilled.yaml\",\n",
    "                prompt=\"a backroom walking\",\n",
    "                height=512,\n",
    "                width=768,\n",
    "                num_frames=fps,\n",
    "                output_path=f\"output_{fps}.mp4\",\n",
    "            )\n",
    "        )\n",
    "        print(f\"{fps} fps - \", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84d557-650a-4c0e-9e72-6d8b8e2f363b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f5a99-847d-4ecd-80f1-bf6c623d0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "ltxv_model_path = hf_hub_download(\n",
    "    repo_id=\"Lightricks/LTX-Video\",\n",
    "    filename=\"./ltxv-2b-0.9.8-distilled-04-25.safetensors\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8557a-d947-45b7-bbfe-2b3c41dbd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3754ab41-7412-4d1c-835e-0a9be971ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltx_video.models.transformers.transformer3d import Transformer3DModel\n",
    "from ltx_video.models.autoencoders.causal_video_autoencoder import CausalVideoAutoencoder\n",
    "\n",
    "ltxv_model_path = './ltxv-2b-0.9.6-distilled-04-25.safetensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff53c33-5733-46d9-8c99-9d4acd3f961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = CausalVideoAutoencoder.from_pretrained(ltxv_model_path)\n",
    "transformer = Transformer3DModel.from_pretrained(ltxv_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f73dd8-a9d6-4b92-abac-8e487cf96dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d09d91160b41d79999a1f1a3b82fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    T5EncoderModel,\n",
    "    T5Tokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoProcessor,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from ltx_video.models.transformers.symmetric_patchifier import SymmetricPatchifier\n",
    "\n",
    "text_encoder_model_name_or_path = \"PixArt-alpha/PixArt-XL-2-1024-MS\"\n",
    "\n",
    "text_encoder = T5EncoderModel.from_pretrained(text_encoder_model_name_or_path, subfolder=\"text_encoder\")\n",
    "patchifier = SymmetricPatchifier(patch_size=1)\n",
    "tokenizer = T5Tokenizer.from_pretrained(text_encoder_model_name_or_path, subfolder=\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f766798-50f2-4262-ab13-07c136ebcc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.1.0+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c721ff0-662a-4a0c-8224-f00fc7267100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 768, 512, 3])\n",
      "torch.Size([1, 3, 33, 768, 512])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_video\n",
    "from einops import rearrange\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "vid_path = './video_output_0_a-cat_171198_768x512x33_0.mp4'\n",
    "\n",
    "# Returns: video(frames), audio, info\n",
    "videot, _, info = read_video(vid_path)\n",
    "\n",
    "print(videot.shape)  # (T, H, W, C)  # T: frame count\n",
    "videot = rearrange(videot.unsqueeze(dim=0), 'b t h w c -> b c t h w').to(device).to(torch.float32)\n",
    "print(videot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c6f748-d99e-4138-8f07-111f2f9d91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "vae = vae.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    aeoutput = vae.encode(videot)\n",
    "    z = aeoutput.latent_dist.sample() # B C T H W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8766ebc-8e2c-4859-8c25-2f171e8f0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ts = torch.tensor([0.95]).to(device)\n",
    "    shapes = torch.tensor([1, 3, 33, 768, 512]).to(device)\n",
    "    \n",
    "    out = vae.decode(z, target_shape=shapes, timestep=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cd107a-e771-4bc0-8adb-2984d9c5e429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 33, 768, 512, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = rearrange(out.sample, 'b c t h w -> b t h w c')\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee0db42-dd89-4ab3-8978-f578d16d96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io import write_video\n",
    "from einops import rearrange\n",
    "\n",
    "video = (video.clamp(0, 1) * 255).to(torch.uint8).cpu()\n",
    "\n",
    "fps = 24\n",
    "write_video('saved_output.mp4', video[0].cpu(), fps=fps, video_codec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4a885-ab33-477d-8a91-f65179357371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecf164-28b7-44f3-a0fc-3e6637a02661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
